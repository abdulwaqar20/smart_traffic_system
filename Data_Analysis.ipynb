{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7e51efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Names:\n",
      " ['ID', 'Source', 'Severity', 'Start_Time', 'End_Time', 'Start_Lat', 'Start_Lng', 'End_Lat', 'End_Lng', 'Distance(mi)', 'Description', 'Street', 'City', 'County', 'State', 'Zipcode', 'Country', 'Timezone', 'Airport_Code', 'Weather_Timestamp', 'Temperature(F)', 'Wind_Chill(F)', 'Humidity(%)', 'Pressure(in)', 'Visibility(mi)', 'Wind_Direction', 'Wind_Speed(mph)', 'Precipitation(in)', 'Weather_Condition', 'Amenity', 'Bump', 'Crossing', 'Give_Way', 'Junction', 'No_Exit', 'Railway', 'Roundabout', 'Station', 'Stop', 'Traffic_Calming', 'Traffic_Signal', 'Turning_Loop', 'Sunrise_Sunset', 'Civil_Twilight', 'Nautical_Twilight', 'Astronomical_Twilight']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load only the header (no data rows)\n",
    "df = pd.read_csv(\"US_Accidents_data.csv\", nrows=2)\n",
    "\n",
    "# Print column names\n",
    "print(\"Column Names:\\n\", df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b435e0ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Source</th>\n",
       "      <th>Severity</th>\n",
       "      <th>Start_Time</th>\n",
       "      <th>End_Time</th>\n",
       "      <th>Start_Lat</th>\n",
       "      <th>Start_Lng</th>\n",
       "      <th>End_Lat</th>\n",
       "      <th>End_Lng</th>\n",
       "      <th>Distance(mi)</th>\n",
       "      <th>...</th>\n",
       "      <th>Roundabout</th>\n",
       "      <th>Station</th>\n",
       "      <th>Stop</th>\n",
       "      <th>Traffic_Calming</th>\n",
       "      <th>Traffic_Signal</th>\n",
       "      <th>Turning_Loop</th>\n",
       "      <th>Sunrise_Sunset</th>\n",
       "      <th>Civil_Twilight</th>\n",
       "      <th>Nautical_Twilight</th>\n",
       "      <th>Astronomical_Twilight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A-1</td>\n",
       "      <td>Source2</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-02-08 05:46:00</td>\n",
       "      <td>2016-02-08 11:00:00</td>\n",
       "      <td>39.865147</td>\n",
       "      <td>-84.058723</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Night</td>\n",
       "      <td>Night</td>\n",
       "      <td>Night</td>\n",
       "      <td>Night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A-2</td>\n",
       "      <td>Source2</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-02-08 06:07:59</td>\n",
       "      <td>2016-02-08 06:37:59</td>\n",
       "      <td>39.928059</td>\n",
       "      <td>-82.831184</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Night</td>\n",
       "      <td>Night</td>\n",
       "      <td>Night</td>\n",
       "      <td>Day</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID   Source  Severity           Start_Time             End_Time  \\\n",
       "0  A-1  Source2         3  2016-02-08 05:46:00  2016-02-08 11:00:00   \n",
       "1  A-2  Source2         2  2016-02-08 06:07:59  2016-02-08 06:37:59   \n",
       "\n",
       "   Start_Lat  Start_Lng  End_Lat  End_Lng  Distance(mi)  ... Roundabout  \\\n",
       "0  39.865147 -84.058723      NaN      NaN          0.01  ...      False   \n",
       "1  39.928059 -82.831184      NaN      NaN          0.01  ...      False   \n",
       "\n",
       "  Station   Stop Traffic_Calming Traffic_Signal Turning_Loop Sunrise_Sunset  \\\n",
       "0   False  False           False          False        False          Night   \n",
       "1   False  False           False          False        False          Night   \n",
       "\n",
       "  Civil_Twilight Nautical_Twilight Astronomical_Twilight  \n",
       "0          Night             Night                 Night  \n",
       "1          Night             Night                   Day  \n",
       "\n",
       "[2 rows x 46 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67d2a0d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random 5000-row sample created with shape: (5000, 46)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "filename = \"US_Accidents_data.csv\"\n",
    "\n",
    "# Step 1: Count total rows (excluding header)\n",
    "with open(filename, 'r', encoding='utf-8') as f:\n",
    "    total_rows = sum(1 for _ in f) - 1  # subtract header\n",
    "\n",
    "# Step 2: Randomly choose rows to **keep**\n",
    "rows_to_skip = sorted(random.sample(range(1, total_rows + 1), total_rows - 5000))\n",
    "\n",
    "# Step 3: Read CSV, skipping unwanted rows\n",
    "df_sample = pd.read_csv(filename, skiprows=rows_to_skip)\n",
    "\n",
    "# Step 4: Save sample if needed\n",
    "df_sample.to_csv(\"US_Accidents_random_sample.csv\", index=False)\n",
    "\n",
    "print(\"Random 5000-row sample created with shape:\", df_sample.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7c8475b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged file created: traffic.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the individual files\n",
    "traffic_data = pd.read_csv(\"traffic_data.csv\")\n",
    "incidents_data = pd.read_csv(\"incidents.csv\")\n",
    "weather_data = pd.read_csv(\"weather_data.csv\")\n",
    "\n",
    "# Merge all three files on 'timestamp' and 'City'\n",
    "merged_df = pd.merge(traffic_data, incidents_data, on=['timestamp', 'City'], how='inner')\n",
    "merged_df = pd.merge(merged_df, weather_data, on=['timestamp', 'City'], how='inner')\n",
    "\n",
    "# Save to a single CSV\n",
    "merged_df.to_csv(\"traffic.csv\", index=False)\n",
    "\n",
    "print(\"Merged file created: traffic.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81169b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error\n",
    "import joblib\n",
    "import os\n",
    "from datetime import datetime\n",
    "from typing import Dict, Optional, Union\n",
    "\n",
    "class TrafficModelTrainer:\n",
    "    def __init__(self, model_path=\"models/traffic_model.pkl\", save_interval=10):\n",
    "        self.model_path = model_path\n",
    "        self.save_interval = save_interval\n",
    "        self.model = None\n",
    "        self.features = None\n",
    "        self.metrics = None\n",
    "        self.last_trained = None\n",
    "        os.makedirs(os.path.dirname(self.model_path), exist_ok=True)\n",
    "\n",
    "    def train_model(self, \n",
    "                   data: pd.DataFrame, \n",
    "                   test_size: float = 0.2, \n",
    "                   n_estimators: int = 100, \n",
    "                   random_state: int = 42,\n",
    "                   verbose: bool = True) -> Optional[Dict]:\n",
    "        try:\n",
    "            if not isinstance(data, pd.DataFrame):\n",
    "                raise ValueError(\"Input data must be a pandas DataFrame\")\n",
    "            if 'congestion_level' not in data.columns:\n",
    "                raise ValueError(\"Target column 'congestion_level' not found in data\")\n",
    "\n",
    "            # Prepare features and target\n",
    "            X = data.drop(columns=['congestion_level', 'timestamp', 'city'], errors='ignore')\n",
    "            y = data['congestion_level']\n",
    "            if X.empty:\n",
    "                raise ValueError(\"No features available for training\")\n",
    "            self.features = list(X.columns)\n",
    "\n",
    "            # Train-test split\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X, y, test_size=test_size, random_state=random_state\n",
    "            )\n",
    "\n",
    "            # Train model\n",
    "            self.model = RandomForestRegressor(\n",
    "                n_estimators=n_estimators,\n",
    "                random_state=random_state,\n",
    "                max_depth=10,\n",
    "                min_samples_split=5,\n",
    "                n_jobs=-1\n",
    "            )\n",
    "            self.model.fit(X_train, y_train)\n",
    "\n",
    "            # Evaluate\n",
    "            y_pred = self.model.predict(X_test)\n",
    "            self.metrics = {\n",
    "                'MAE': round(mean_absolute_error(y_test, y_pred), 2),\n",
    "                'R2': round(r2_score(y_test, y_pred), 2),\n",
    "                'RMSE': round(mean_squared_error(y_test, y_pred, squared=False), 2)\n",
    "            }\n",
    "\n",
    "            # Metadata\n",
    "            self.last_trained = datetime.now()\n",
    "\n",
    "            # Save model\n",
    "            saved = self._save_model(verbose=verbose)\n",
    "            if not saved:\n",
    "                raise RuntimeError(\"❌ Model training succeeded but saving failed.\")\n",
    "\n",
    "            if verbose:\n",
    "                print(f\"✅ Training completed at {self.last_trained}\")\n",
    "                print(f\"📊 Metrics: {self.metrics}\")\n",
    "                print(f\"📦 Saved to: {self.model_path}\")\n",
    "\n",
    "            return {\n",
    "                'model': self.model,\n",
    "                'metrics': self.metrics,\n",
    "                'features': self.features,\n",
    "                'last_trained': self.last_trained\n",
    "            }\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Training error: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    def _save_model(self, verbose: bool = True) -> bool:\n",
    "        try:\n",
    "            model_data = {\n",
    "                'model': self.model,\n",
    "                'features': self.features,\n",
    "                'metrics': self.metrics,\n",
    "                'last_trained': self.last_trained\n",
    "            }\n",
    "            print(f\"🔄 Saving model to: {os.path.abspath(self.model_path)}\")\n",
    "            joblib.dump(model_data, self.model_path)\n",
    "            if verbose:\n",
    "                print(f\"💾 Model saved successfully to {self.model_path}\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Failed to save model: {str(e)}\")\n",
    "            return False\n",
    "\n",
    "    def load_model(self) -> Optional[RandomForestRegressor]:\n",
    "        try:\n",
    "            if not os.path.exists(self.model_path):\n",
    "                print(\"⚠️ Model file not found.\")\n",
    "                return None\n",
    "\n",
    "            model_data = joblib.load(self.model_path)\n",
    "            if isinstance(model_data, dict):\n",
    "                self.model = model_data.get('model')\n",
    "                self.features = model_data.get('features')\n",
    "                self.metrics = model_data.get('metrics')\n",
    "                self.last_trained = model_data.get('last_trained')\n",
    "            else:\n",
    "                self.model = model_data\n",
    "\n",
    "            print(f\"✅ Model loaded (trained on {self.last_trained})\")\n",
    "            return self.model\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Model loading failed: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    def predict(self, input_data: Union[pd.DataFrame, dict], verbose: bool = True) -> Optional[Union[float, list]]:\n",
    "        try:\n",
    "            if self.model is None and not self.load_model():\n",
    "                raise ValueError(\"No model available for prediction\")\n",
    "\n",
    "            if isinstance(input_data, dict):\n",
    "                input_data = pd.DataFrame([input_data])\n",
    "\n",
    "            missing_features = [f for f in self.features if f not in input_data.columns]\n",
    "            if missing_features:\n",
    "                raise ValueError(f\"Missing features: {missing_features}\")\n",
    "\n",
    "            X = input_data[self.features]\n",
    "            predictions = self.model.predict(X)\n",
    "\n",
    "            if verbose:\n",
    "                print(f\"🔮 Prediction made using model trained on {self.last_trained}\")\n",
    "                if len(predictions) == 1:\n",
    "                    print(f\"📊 Predicted congestion level: {predictions[0]:.2f}%\")\n",
    "\n",
    "            return predictions[0] if len(predictions) == 1 else predictions\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Prediction error: {str(e)}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8d59fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 'incident_count' column with random values.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load your existing CSV\n",
    "df = pd.read_csv(\"data/traffic.csv\")\n",
    "\n",
    "# Add a new column 'incident_count' with random integers (e.g., 0 to 5)\n",
    "np.random.seed(42)  # for reproducibility\n",
    "df['incident_count'] = np.random.randint(0, 6, size=len(df))\n",
    "\n",
    "# Save the updated CSV back\n",
    "df.to_csv(\"data/traffic_with_incident_count.csv\", index=False)\n",
    "\n",
    "print(\"Added 'incident_count' column with random values.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a616d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📄 Loaded dataset with shape: (5006, 16)\n",
      "📋 Columns in CSV: ['timestamp', 'City', 'latitude', 'longitude', 'severity_x', 'free_flow_speed', 'current_speed', 'is_congested', 'Severity_y', 'description', 'distance', 'temperature', 'humidity', 'precipitation', 'weather_condition', 'incident_count']\n",
      "🚦 Starting model training...\n",
      "✅ Model training completed.\n",
      "💾 Model saved to: traffic_model.pkl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def train_and_save_model(csv_path, model_path=\"traffic_model.pkl\"):\n",
    "    try:\n",
    "        # Load the dataset\n",
    "        data = pd.read_csv(csv_path)\n",
    "        print(f\"📄 Loaded dataset with shape: {data.shape}\")\n",
    "        print(\"📋 Columns in CSV:\", data.columns.tolist())\n",
    "\n",
    "        target_col = \"is_congested\"\n",
    "\n",
    "        # Check if target column exists\n",
    "        if target_col not in data.columns:\n",
    "            print(f\"❌ '{target_col}' column not found in data.\")\n",
    "            return False\n",
    "\n",
    "        # Drop rows with missing target\n",
    "        data = data.dropna(subset=[target_col])\n",
    "\n",
    "        # Drop non-numeric and irrelevant columns\n",
    "        drop_cols = [\"timestamp\", \"Description\"]  # Drop text/date columns\n",
    "        data = data.drop(columns=[col for col in drop_cols if col in data.columns])\n",
    "\n",
    "        # Label encode categorical columns\n",
    "        cat_cols = data.select_dtypes(include=[\"object\"]).columns\n",
    "        le_dict = {}\n",
    "        for col in cat_cols:\n",
    "            le = LabelEncoder()\n",
    "            data[col] = le.fit_transform(data[col].astype(str))\n",
    "            le_dict[col] = le\n",
    "\n",
    "        # Split features and target\n",
    "        X = data.drop(columns=[target_col])\n",
    "        y = data[target_col]\n",
    "\n",
    "        # Split into train and test sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        # Train model\n",
    "        print(\"🚦 Starting model training...\")\n",
    "        model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "        model.fit(X_train, y_train)\n",
    "        print(\"✅ Model training completed.\")\n",
    "\n",
    "        # Save model\n",
    "        joblib.dump(model, model_path)\n",
    "        print(f\"💾 Model saved to: {model_path}\")\n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error: {e}\")\n",
    "        return False\n",
    "\n",
    "# Run the training\n",
    "train_and_save_model(\"data/traffic.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b0dabd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
